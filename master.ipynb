{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VzBQqm7h6fCJ","executionInfo":{"status":"ok","timestamp":1677477321824,"user_tz":420,"elapsed":36528,"user":{"displayName":"Mogileeswar Reddy Morramreddygari","userId":"16901409376116222916"}},"outputId":"1ba1aeab-335f-42c7-e08f-ff243a0bb404"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["Path = \"drive/Shared drives/Data_Mining_Final_Project/\""],"metadata":{"id":"_l9ju2tJ7FoX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import os\n","import numpy as np\n","!git clone https://github.com/ntasfi/PyGame-Learning-Environment.git\n","!cd PyGame-Learning-Environment/ && pip install .\n","!pip install -q pygame\n","import os\n","os.environ['SDL_AUDIODRIVER'] = 'dummy'\n","import pygame.mixer\n","import time\n","from keras.models import model_from_json\n","import imutils\n","from keras.models import load_model\n","from tensorflow.keras.utils import load_img\n","from tensorflow.keras.utils import img_to_array\n","from PIL import Image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RST9vES-7Nk8","executionInfo":{"status":"ok","timestamp":1677477346431,"user_tz":420,"elapsed":15067,"user":{"displayName":"Mogileeswar Reddy Morramreddygari","userId":"16901409376116222916"}},"outputId":"a6cd331a-5022-400e-dbb1-2d838ce973d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'PyGame-Learning-Environment'...\n","remote: Enumerating objects: 1118, done.\u001b[K\n","remote: Total 1118 (delta 0), reused 0 (delta 0), pack-reused 1118\u001b[K\n","Receiving objects: 100% (1118/1118), 8.06 MiB | 12.31 MiB/s, done.\n","Resolving deltas: 100% (592/592), done.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/PyGame-Learning-Environment\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ple==0.0.1) (1.22.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from ple==0.0.1) (7.1.2)\n","Building wheels for collected packages: ple\n","  Building wheel for ple (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ple: filename=ple-0.0.1-py3-none-any.whl size=50789 sha256=eab64bcc91429c4482798038bfc854150cf64b7e140d041318c4fbf681fb7616\n","  Stored in directory: /root/.cache/pip/wheels/a5/b3/ea/821601ded534b006191679eb36f637db13521f7d48bbcfd8bf\n","Successfully built ple\n","Installing collected packages: ple\n","Successfully installed ple-0.0.1\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hpygame 2.1.3 (SDL 2.0.22, Python 3.8.10)\n","Hello from the pygame community. https://www.pygame.org/contribute.html\n"]}]},{"cell_type":"code","source":["pygame.mixer.quit()\n","pygame.mixer.init()\n","sound = pygame.mixer.Sound(Path+\"alarm.wav\")\n","\n","\n","face = cv2.CascadeClassifier(Path+\"haar cascade files\\haarcascade_frontalface_alt.xml\")\n","leye = cv2.CascadeClassifier(Path+\"haar cascade files\\haarcascade_lefteye_2splits.xml\")\n","reye = cv2.CascadeClassifier(Path+\"haar cascade files\\haarcascade_righteye_2splits.xml\")\n","detection_model_path = Path+\"haar cascade files\\haarcascade_frontalface_default.xml\"\n","emotion_model_path = Path+\"models/model2.hdf5\"\n","heart_model_path = Path+\"models/model3.h5\"\n","eye_model_path =  Path+\"models/model1.h5\""],"metadata":{"id":"Pz61ofOy9FKe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","face_detection = cv2.CascadeClassifier(detection_model_path)\n","EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n","WIDTH, HEIGHT = 256, 256        # Size images to train\n","CLASS_COUNTING = True           # Test class per class and show details each \n","BATCH_SIZE = 32                 # How many images at the same time, change depending on your GPU\n","CLASSES = ['Infrant', 'None']   # Classes to detect. they most be in same position with output vector\n","\n","# def loadModel(model_path, weight_path):\n","#     json_file = open(model_path, 'r')\n","#     loaded_model_json = json_file.read()\n","#     json_file.close()\n","#     model = model_from_json(loaded_model_json)\n","#     # load weights into new model\n","#     model.load_weights(weight_path)\n","#     # evaluate loaded model on test data\n","#     model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","#     return model\n","\n","# model = loadModel('models/model1.json', \"models/model1.h5\")\n","\n","emotion_model = load_model(emotion_model_path, compile=False)\n","model = load_model(eye_model_path)\n","heart_model = load_model(heart_model_path)\n","\n","#cv2.namedWindow('your_face')\n","path = os.getcwd()\n","cap = cv2.VideoCapture(0)\n","font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n","count=0\n","score=0\n","fscore=0\n","escore=0\n","thicc=2\n","rpred=[99]\n","lpred=[99]\n","c=0\n","\n","\n","while(True):\n","    ret, frame = cap.read()\n","    frame = cv2.flip(frame, 1)\n","    height,width = frame.shape[:2] \n","\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    \n","    faces = face.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(25,25))\n","    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n","    \n","    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n","    frameClone = frame.copy()\n","    \n","    left_eye = leye.detectMultiScale(gray)\n","    right_eye =  reye.detectMultiScale(gray)\n","    \n","    frame_c = frame.copy()\n","    x = cv2.resize(frame_c, (WIDTH, HEIGHT))\n","    x = img_to_array(x)\n","    x = np.expand_dims(x, axis=0)\n","    array = heart_model.predict(x)\n","    result = array[0]\n","    answer = np.argmax(result)\n","\n","    cv2.rectangle(frame, (0,height-50) , (200,height) , (0,0,0) , thickness=cv2.FILLED )\n","\n","    for (x,y,w,h) in faces:\n","        cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 1 )\n","\n","    for (x,y,w,h) in right_eye:\n","        r_eye=frame[y:y+h,x:x+w]\n","        count=count+1\n","        r_eye = cv2.cvtColor(r_eye,cv2.COLOR_BGR2GRAY)\n","        r_eye = cv2.resize(r_eye,(24,24))\n","        r_eye= r_eye/255\n","        r_eye=  r_eye.reshape(24,24,-1)\n","        r_eye = np.expand_dims(r_eye,axis=0)\n","        rpred = model.predict_classes(r_eye)\n","        break\n","\n","    for (x,y,w,h) in left_eye:\n","        l_eye=frame[y:y+h,x:x+w]\n","        count=count+1\n","        l_eye = cv2.cvtColor(l_eye,cv2.COLOR_BGR2GRAY)  \n","        l_eye = cv2.resize(l_eye,(24,24))\n","        l_eye= l_eye/255\n","        l_eye=l_eye.reshape(24,24,-1)\n","        l_eye = np.expand_dims(l_eye,axis=0)\n","        lpred = model.predict_classes(l_eye)\n","        break\n","    \n","    if(CLASSES[answer]=='Infrant'):\n","        c+=1\n","    else:\n","        c=0\n","        \n","    cv2.putText(frame,'body_score:'+str(c),(10,75), font, 1,(236,216,31),1,cv2.LINE_AA)\n","    \n","    if len(faces) > 0:\n","        faces = sorted(faces, reverse=True,\n","        key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n","        (fX, fY, fW, fH) = faces\n","\n","        roi = gray[fY:fY + fH, fX:fX + fW]\n","        roi = cv2.resize(roi, (64, 64))\n","        roi = roi.astype(\"float\") / 255.0\n","        roi = img_to_array(roi)\n","        roi = np.expand_dims(roi, axis=0)\n","        \n","        \n","        preds = emotion_model.predict(roi)[0]\n","        emotion_probability = np.max(preds)\n","        label = EMOTIONS[preds.argmax()]\n","        cv2.putText(frame,label,(500,40), font, 1,(0,0,255),1,cv2.LINE_AA)\n","        if label==\"scared\" or label==\"disgust\":\n","            escore+=2\n","        else:\n","            if escore>0:\n","                escore-=1\n","            else:\n","                escore=0\n","    cv2.putText(frame,'Emotion_Score:'+str(escore),(10,100), font, 1,(236,216,31),1,cv2.LINE_AA)\n","    \n","    if len(faces)==0:\n","        fscore+=1\n","        cv2.putText(frame,\"Cannot find face\",(400,20), font, 1,(0,0,255),1,cv2.LINE_AA)\n","    elif(rpred[0]==0 and lpred[0]==0):\n","        fscore-=1\n","        score=score+1\n","        cv2.putText(frame,\"Closed\",(500,20), font, 1,(0,0,255),1,cv2.LINE_AA)\n","    # if(rpred[0]==1 or lpred[0]==1):\n","    else:\n","        fscore-=1\n","        score=score-1\n","        cv2.putText(frame,\"Open\",(500,20), font, 1,(0,0,255),1,cv2.LINE_AA)\n","     \n","    if score<0:\n","        score=0\n","    if fscore<0:\n","        fscore=0\n","    cv2.putText(frame,'Eye_Score:'+str(score),(10,25), font, 1,(236,216,31),1,cv2.LINE_AA)\n","    cv2.putText(frame,'Face_Score:'+str(fscore),(10,50), font, 1,(236,216,31),1,cv2.LINE_AA)\n","    \n","    if (score>15 or fscore>20 or escore>3 or (c>15 and (len(faces)==0 or (rpred==0 and lpred==0)))):\n","        #person is feeling sleepy so we beep the alarm\n","        cv2.imwrite(os.path.join(path,'image.jpg'),frame)\n","        try:\n","            sound.play()\n","            \n","        except:  # isplaying = False\n","            pass\n","        if(thicc<16):\n","            thicc= thicc+2\n","        else:\n","            thicc=thicc-2\n","            if(thicc<2):\n","                thicc=2\n","        cv2.rectangle(frame,(0,0),(width,height),(21,240,80),thicc) \n","    cv2.imshow('frame',frame)\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","cap.release()\n","cv2.destroyAllWindows()"],"metadata":{"id":"ubxXgFauGhwh"},"execution_count":null,"outputs":[]}]}